{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Traffic sign detection using YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Kaggle data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "def apply_augmentations(image):\n",
    "    \"\"\"Applies random augmentations to the given image and returns a list of augmented images.\"\"\"\n",
    "    augmentations = []\n",
    "\n",
    "    # Add Gaussian Noise\n",
    "    def add_noise(img):\n",
    "        row, col, ch = img.shape\n",
    "        mean = 0\n",
    "        sigma = 0.1\n",
    "        gauss = np.random.normal(mean, sigma, (row, col, ch)).astype('float32')\n",
    "        noisy = img + gauss * 255\n",
    "        return np.clip(noisy, 0, 255).astype('uint8')\n",
    "\n",
    "    # Change Brightness\n",
    "    def change_brightness(img):\n",
    "        factor = random.uniform(0.5, 1.5)  # random brightness factor\n",
    "        enhancer = ImageEnhance.Brightness(Image.fromarray(img))\n",
    "        return np.array(enhancer.enhance(factor))\n",
    "\n",
    "    # Change Contrast\n",
    "    def change_contrast(img):\n",
    "        factor = random.uniform(0.5, 1.5)  # random contrast factor\n",
    "        enhancer = ImageEnhance.Contrast(Image.fromarray(img))\n",
    "        return np.array(enhancer.enhance(factor))\n",
    "\n",
    "    # Change Saturation\n",
    "    def change_saturation(img):\n",
    "        factor = random.uniform(0.5, 1.5)  # random saturation factor\n",
    "        enhancer = ImageEnhance.Color(Image.fromarray(img))\n",
    "        return np.array(enhancer.enhance(factor))\n",
    "\n",
    "    # Apply Gaussian Blur\n",
    "    def apply_gaussian_blur(img):\n",
    "        ksize = random.choice([3, 5, 7])  # random kernel size\n",
    "        return cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
    "\n",
    "    # Apply augmentations\n",
    "    augmentations.append(add_noise(image))\n",
    "    augmentations.append(change_brightness(image))\n",
    "    augmentations.append(change_contrast(image))\n",
    "    augmentations.append(change_saturation(image))\n",
    "    augmentations.append(apply_gaussian_blur(image))\n",
    "\n",
    "    return augmentations\n",
    "\n",
    "def augment_image_and_save(image_path, label_path, output_dir):\n",
    "    label_output_dir=f'{output_dir}/labels'\n",
    "    image_output_dir=f'{output_dir}/images'\n",
    "    create_folder(output_dir)\n",
    "    create_folder(label_output_dir)\n",
    "    create_folder(image_output_dir)\n",
    "    # Read image and label\n",
    "    image = cv2.imread(image_path)\n",
    "    with open(label_path, 'r') as f:\n",
    "        label = f.read()\n",
    "\n",
    "    # Resize image to 512x512\n",
    "    image_resized = cv2.resize(image, (512, 512))\n",
    "\n",
    "    # Apply augmentations\n",
    "    augmented_images = apply_augmentations(image_resized)\n",
    "\n",
    "    # Get base name of the file (without extension)\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    # Save augmented images and corresponding labels\n",
    "    for i, augmented_image in enumerate(augmented_images):\n",
    "        # Construct new file names\n",
    "        new_image_name = f\"{image_output_dir}/{base_name}_{i+1}.jpg\"\n",
    "        new_label_name = f\"{label_output_dir}/{base_name}_{i+1}.txt\"\n",
    "        \n",
    "        # Save augmented image\n",
    "        new_image_path = os.path.join(output_dir, new_image_name)\n",
    "        cv2.imwrite(new_image_path, augmented_image)\n",
    "        \n",
    "        # Save corresponding label\n",
    "        new_label_path = os.path.join(output_dir, new_label_name)\n",
    "        with open(new_label_path, 'w') as f:\n",
    "            f.write(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(label_file):\n",
    "    with open(label_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        labels = [int(line.split()[0]) for line in lines]\n",
    "    return labels\n",
    "\n",
    "def split_dataset(image_dir, label_dir, output_dir, train_ratio, val_ratio):\n",
    "    # Create train and val directories for images and labels\n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    val_dir = os.path.join(output_dir, 'val')\n",
    "    # Collect all files and their labels\n",
    "    files_labels = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            label_path = os.path.join(label_dir, filename.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "            if os.path.exists(label_path):  # Ensure corresponding label file exists\n",
    "                labels = get_labels(label_path)\n",
    "                files_labels.append((image_path, label_path, labels))\n",
    "\n",
    "    # Shuffle files to ensure randomness\n",
    "    random.shuffle(files_labels)\n",
    "\n",
    "    # Track class distribution in each split\n",
    "    class_counts = {\n",
    "        'train': defaultdict(int),\n",
    "        'val': defaultdict(int)\n",
    "    }\n",
    "\n",
    "    total_class_counts = defaultdict(int)\n",
    "\n",
    "    # Assign files to splits\n",
    "    splits = {'train': [], 'val': []}\n",
    "    for image_path, label_path, labels in files_labels:\n",
    "        for label in labels:\n",
    "            total_class_counts[label] += 1\n",
    "\n",
    "    for image_path, label_path, labels in files_labels:\n",
    "        # Ensure train set has at least 50% of each class\n",
    "        if all(class_counts['train'][label] >= 0.5 * total_class_counts[label] for label in labels):\n",
    "            chosen_split = 'val'\n",
    "        else:\n",
    "            chosen_split = 'train'\n",
    "        \n",
    "        splits[chosen_split].append((image_path, label_path, labels))\n",
    "        for label in labels:\n",
    "            class_counts[chosen_split][label] += 1\n",
    "\n",
    "    # Adjust to ensure train_ratio\n",
    "    train_size = int(train_ratio * len(files_labels))\n",
    "    while len(splits['train']) < train_size:\n",
    "        item = splits['val'].pop()\n",
    "        splits['train'].append(item)\n",
    "        labels = item[2]\n",
    "        for label in labels:\n",
    "            class_counts['train'][label] += 1\n",
    "            class_counts['val'][label] -= 1\n",
    "\n",
    "    # Copy files to the appropriate directories\n",
    "    for split, files in splits.items():\n",
    "        for image_path, label_path, _ in files:\n",
    "            if split == 'train':\n",
    "                augment_image_and_save(image_path,label_path,train_dir)\n",
    "            elif split == 'val':\n",
    "                augment_image_and_save(image_path,label_path,val_dir)\n",
    "\n",
    "    # Calculate and print class distribution percentages\n",
    "    print(\"Class Distribution Percentages:\")\n",
    "    for split in ['train', 'val']:\n",
    "        print(f\"\\n{split.capitalize()} Set:\")\n",
    "        for label, count in class_counts[split].items():\n",
    "            percentage = (count / total_class_counts[label]) * 100 if total_class_counts[label] > 0 else 0\n",
    "            print(f\"Class {label}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir=\"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/data/trafficsign/images\"\n",
    "label_dir =\"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/data/trafficsign/lables\"\n",
    "output_dir = \"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/data/datasplit_sign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "val_ratio = 0.1  # Adjusted to fill remaining data after train\n",
    "\n",
    "# Call the split_dataset function\n",
    "split_dataset(image_dir, label_dir, output_dir, train_ratio, val_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Roboflow data (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {ROOT}/src/traffic_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"Q8lgh4wyEXLBUcnFKIwe\")\n",
    "project = rf.workspace(\"vietnam-traffic-sign-detection\").project(\"vietnam-traffic-sign-detection-2i2j8\")\n",
    "version = project.version(6)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=640 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = \"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/src/traffic_sign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yolo task=detect mode=predict model=best.pt conf=0.25 source=D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/src/traffic_sign/Vietnam-Traffic-Sign-Detection-6/test/images save=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd D:\\DatTruong\\All\\2025\\AI_Engineer\\20.Project\\4.Autonomous_Vehicle\\src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd D:\\DatTruong\\All\\2025\\AI_Engineer\\20.Project\\4.Autonomous_Vehicle\\src\\yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights best.pt --img 640 --conf 0.25 --source test_sign.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
