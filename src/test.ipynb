{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Traffic sign detection using YOLOv8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Kaggle data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import random\n",
    "import shutil\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "def apply_augmentations(image):\n",
    "    \"\"\"Applies random augmentations to the given image and returns a list of augmented images.\"\"\"\n",
    "    augmentations = []\n",
    "\n",
    "    # Add Gaussian Noise\n",
    "    def add_noise(img):\n",
    "        row, col, ch = img.shape\n",
    "        mean = 0\n",
    "        sigma = 0.1\n",
    "        gauss = np.random.normal(mean, sigma, (row, col, ch)).astype('float32')\n",
    "        noisy = img + gauss * 255\n",
    "        return np.clip(noisy, 0, 255).astype('uint8')\n",
    "\n",
    "    # Change Brightness\n",
    "    def change_brightness(img):\n",
    "        factor = random.uniform(0.5, 1.5)  # random brightness factor\n",
    "        enhancer = ImageEnhance.Brightness(Image.fromarray(img))\n",
    "        return np.array(enhancer.enhance(factor))\n",
    "\n",
    "    # Change Contrast\n",
    "    def change_contrast(img):\n",
    "        factor = random.uniform(0.5, 1.5)  # random contrast factor\n",
    "        enhancer = ImageEnhance.Contrast(Image.fromarray(img))\n",
    "        return np.array(enhancer.enhance(factor))\n",
    "\n",
    "    # Change Saturation\n",
    "    def change_saturation(img):\n",
    "        factor = random.uniform(0.5, 1.5)  # random saturation factor\n",
    "        enhancer = ImageEnhance.Color(Image.fromarray(img))\n",
    "        return np.array(enhancer.enhance(factor))\n",
    "\n",
    "    # Apply Gaussian Blur\n",
    "    def apply_gaussian_blur(img):\n",
    "        ksize = random.choice([3, 5, 7])  # random kernel size\n",
    "        return cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
    "\n",
    "    # Apply augmentations\n",
    "    augmentations.append(add_noise(image))\n",
    "    augmentations.append(change_brightness(image))\n",
    "    augmentations.append(change_contrast(image))\n",
    "    augmentations.append(change_saturation(image))\n",
    "    augmentations.append(apply_gaussian_blur(image))\n",
    "\n",
    "    return augmentations\n",
    "\n",
    "def augment_image_and_save(image_path, label_path, output_dir):\n",
    "    label_output_dir=f'{output_dir}/labels'\n",
    "    image_output_dir=f'{output_dir}/images'\n",
    "    create_folder(output_dir)\n",
    "    create_folder(label_output_dir)\n",
    "    create_folder(image_output_dir)\n",
    "    # Read image and label\n",
    "    image = cv2.imread(image_path)\n",
    "    with open(label_path, 'r') as f:\n",
    "        label = f.read()\n",
    "\n",
    "    # Resize image to 512x512\n",
    "    image_resized = cv2.resize(image, (512, 512))\n",
    "\n",
    "    # Apply augmentations\n",
    "    augmented_images = apply_augmentations(image_resized)\n",
    "\n",
    "    # Get base name of the file (without extension)\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    # Save augmented images and corresponding labels\n",
    "    for i, augmented_image in enumerate(augmented_images):\n",
    "        # Construct new file names\n",
    "        new_image_name = f\"{image_output_dir}/{base_name}_{i+1}.jpg\"\n",
    "        new_label_name = f\"{label_output_dir}/{base_name}_{i+1}.txt\"\n",
    "        \n",
    "        # Save augmented image\n",
    "        new_image_path = os.path.join(output_dir, new_image_name)\n",
    "        cv2.imwrite(new_image_path, augmented_image)\n",
    "        \n",
    "        # Save corresponding label\n",
    "        new_label_path = os.path.join(output_dir, new_label_name)\n",
    "        with open(new_label_path, 'w') as f:\n",
    "            f.write(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(label_file):\n",
    "    with open(label_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        labels = [int(line.split()[0]) for line in lines]\n",
    "    return labels\n",
    "\n",
    "def split_dataset(image_dir, label_dir, output_dir, train_ratio, val_ratio):\n",
    "    # Create train and val directories for images and labels\n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    val_dir = os.path.join(output_dir, 'val')\n",
    "    # Collect all files and their labels\n",
    "    files_labels = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            label_path = os.path.join(label_dir, filename.replace('.jpg', '.txt').replace('.png', '.txt'))\n",
    "            if os.path.exists(label_path):  # Ensure corresponding label file exists\n",
    "                labels = get_labels(label_path)\n",
    "                files_labels.append((image_path, label_path, labels))\n",
    "\n",
    "    # Shuffle files to ensure randomness\n",
    "    random.shuffle(files_labels)\n",
    "\n",
    "    # Track class distribution in each split\n",
    "    class_counts = {\n",
    "        'train': defaultdict(int),\n",
    "        'val': defaultdict(int)\n",
    "    }\n",
    "\n",
    "    total_class_counts = defaultdict(int)\n",
    "\n",
    "    # Assign files to splits\n",
    "    splits = {'train': [], 'val': []}\n",
    "    for image_path, label_path, labels in files_labels:\n",
    "        for label in labels:\n",
    "            total_class_counts[label] += 1\n",
    "\n",
    "    for image_path, label_path, labels in files_labels:\n",
    "        # Ensure train set has at least 50% of each class\n",
    "        if all(class_counts['train'][label] >= 0.5 * total_class_counts[label] for label in labels):\n",
    "            chosen_split = 'val'\n",
    "        else:\n",
    "            chosen_split = 'train'\n",
    "        \n",
    "        splits[chosen_split].append((image_path, label_path, labels))\n",
    "        for label in labels:\n",
    "            class_counts[chosen_split][label] += 1\n",
    "\n",
    "    # Adjust to ensure train_ratio\n",
    "    train_size = int(train_ratio * len(files_labels))\n",
    "    while len(splits['train']) < train_size:\n",
    "        item = splits['val'].pop()\n",
    "        splits['train'].append(item)\n",
    "        labels = item[2]\n",
    "        for label in labels:\n",
    "            class_counts['train'][label] += 1\n",
    "            class_counts['val'][label] -= 1\n",
    "\n",
    "    # Copy files to the appropriate directories\n",
    "    for split, files in splits.items():\n",
    "        for image_path, label_path, _ in files:\n",
    "            if split == 'train':\n",
    "                augment_image_and_save(image_path,label_path,train_dir)\n",
    "            elif split == 'val':\n",
    "                augment_image_and_save(image_path,label_path,val_dir)\n",
    "\n",
    "    # Calculate and print class distribution percentages\n",
    "    print(\"Class Distribution Percentages:\")\n",
    "    for split in ['train', 'val']:\n",
    "        print(f\"\\n{split.capitalize()} Set:\")\n",
    "        for label, count in class_counts[split].items():\n",
    "            percentage = (count / total_class_counts[label]) * 100 if total_class_counts[label] > 0 else 0\n",
    "            print(f\"Class {label}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir=\"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/data/trafficsign/images\"\n",
    "label_dir =\"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/data/trafficsign/lables\"\n",
    "output_dir = \"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/data/datasplit_sign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/data/trafficsign/images'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m val_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# Adjusted to fill remaining data after train\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Call the split_dataset function\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43msplit_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m, in \u001b[0;36msplit_dataset\u001b[1;34m(image_dir, label_dir, output_dir, train_ratio, val_ratio)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Collect all files and their labels\u001b[39;00m\n\u001b[0;32m     12\u001b[0m files_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     15\u001b[0m         image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_dir, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/data/trafficsign/images'"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9\n",
    "val_ratio = 0.1  # Adjusted to fill remaining data after train\n",
    "\n",
    "# Call the split_dataset function\n",
    "split_dataset(image_dir, label_dir, output_dir, train_ratio, val_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Roboflow data (main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"D:/DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\DatTruong\\All\\2025\\AI_Engineer\\20.Project\\4.Autonomous_Vehicle\\src\\traffic_sign\n"
     ]
    }
   ],
   "source": [
    "%cd {ROOT}/src/traffic_sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.2.51, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Vietnam-Traffic-Sign-Detection-6 to yolov8::   1%|▏         | 3967/268344 [00:06<07:14, 608.58it/s]"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"Q8lgh4wyEXLBUcnFKIwe\")\n",
    "project = rf.workspace(\"vietnam-traffic-sign-detection\").project(\"vietnam-traffic-sign-detection-2i2j8\")\n",
    "version = project.version(6)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\DatTruong\\\\All\\\\2025\\\\AI_Engineer\\\\20.Project\\\\4.Autonomous_Vehicle\\\\src\\\\Vietnam-Traffic-Sign-Detection-6'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  Ultralytics settings reset to default values. This may be due to a possible problem with your settings or a recent ultralytics package update. \n",
      "View settings with 'yolo settings' or at 'C:\\Users\\ADMIN\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n",
      "Update settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt to 'yolov8s.pt'...\n",
      "\n",
      "  0%|          | 0.00/21.5M [00:00<?, ?B/s]\n",
      "  1%|          | 128k/21.5M [00:00<00:32, 689kB/s]\n",
      "  1%|          | 256k/21.5M [00:00<00:34, 646kB/s]\n",
      "  2%|▏         | 384k/21.5M [00:00<00:34, 641kB/s]\n",
      "  2%|▏         | 512k/21.5M [00:00<00:35, 630kB/s]\n",
      "  3%|▎         | 640k/21.5M [00:01<00:34, 628kB/s]\n",
      "  3%|▎         | 768k/21.5M [00:01<00:34, 629kB/s]\n",
      "  4%|▍         | 896k/21.5M [00:01<00:34, 625kB/s]\n",
      "  5%|▍         | 1.00M/21.5M [00:01<00:33, 652kB/s]\n",
      "  5%|▌         | 1.12M/21.5M [00:01<00:33, 639kB/s]\n",
      "  6%|▌         | 1.25M/21.5M [00:02<00:33, 632kB/s]\n",
      "  6%|▋         | 1.38M/21.5M [00:02<00:33, 640kB/s]\n",
      "  7%|▋         | 1.50M/21.5M [00:02<00:34, 616kB/s]\n",
      "  8%|▊         | 1.62M/21.5M [00:02<00:31, 665kB/s]\n",
      "  8%|▊         | 1.75M/21.5M [00:02<00:33, 623kB/s]\n",
      "  9%|▊         | 1.88M/21.5M [00:03<00:33, 624kB/s]\n",
      "  9%|▉         | 2.00M/21.5M [00:03<00:31, 649kB/s]\n",
      " 10%|▉         | 2.12M/21.5M [00:03<00:31, 644kB/s]\n",
      " 10%|█         | 2.25M/21.5M [00:03<00:32, 631kB/s]\n",
      " 11%|█         | 2.38M/21.5M [00:03<00:31, 631kB/s]\n",
      " 12%|█▏        | 2.50M/21.5M [00:04<00:31, 626kB/s]\n",
      " 12%|█▏        | 2.62M/21.5M [00:04<00:31, 625kB/s]\n",
      " 13%|█▎        | 2.75M/21.5M [00:04<00:30, 653kB/s]\n",
      " 13%|█▎        | 2.88M/21.5M [00:04<00:30, 645kB/s]\n",
      " 14%|█▍        | 3.00M/21.5M [00:04<00:30, 639kB/s]\n",
      " 15%|█▍        | 3.12M/21.5M [00:05<00:30, 632kB/s]\n",
      " 15%|█▌        | 3.25M/21.5M [00:05<00:30, 635kB/s]\n",
      " 16%|█▌        | 3.38M/21.5M [00:05<00:30, 630kB/s]\n",
      " 16%|█▋        | 3.50M/21.5M [00:05<00:28, 656kB/s]\n",
      " 17%|█▋        | 3.62M/21.5M [00:05<00:29, 639kB/s]\n",
      " 17%|█▋        | 3.75M/21.5M [00:06<00:29, 638kB/s]\n",
      " 18%|█▊        | 3.88M/21.5M [00:06<00:29, 636kB/s]\n",
      " 19%|█▊        | 4.00M/21.5M [00:06<00:29, 632kB/s]\n",
      " 19%|█▉        | 4.12M/21.5M [00:06<00:27, 656kB/s]\n",
      " 20%|█▉        | 4.25M/21.5M [00:06<00:28, 646kB/s]\n",
      " 20%|██        | 4.38M/21.5M [00:07<00:28, 641kB/s]\n",
      " 21%|██        | 4.50M/21.5M [00:07<00:27, 638kB/s]\n",
      " 21%|██▏       | 4.62M/21.5M [00:07<00:28, 632kB/s]\n",
      " 22%|██▏       | 4.75M/21.5M [00:07<00:27, 629kB/s]\n",
      " 23%|██▎       | 4.88M/21.5M [00:07<00:26, 657kB/s]\n",
      " 23%|██▎       | 5.00M/21.5M [00:08<00:26, 644kB/s]\n",
      " 24%|██▍       | 5.12M/21.5M [00:08<00:26, 640kB/s]\n",
      " 24%|██▍       | 5.25M/21.5M [00:08<00:27, 626kB/s]\n",
      " 25%|██▍       | 5.38M/21.5M [00:08<00:26, 632kB/s]\n",
      " 26%|██▌       | 5.50M/21.5M [00:09<00:26, 630kB/s]\n",
      " 26%|██▌       | 5.62M/21.5M [00:09<00:25, 659kB/s]\n",
      " 27%|██▋       | 5.75M/21.5M [00:09<00:25, 646kB/s]\n",
      " 27%|██▋       | 5.88M/21.5M [00:09<00:25, 637kB/s]\n",
      " 28%|██▊       | 6.00M/21.5M [00:09<00:25, 637kB/s]\n",
      " 28%|██▊       | 6.12M/21.5M [00:10<00:25, 633kB/s]\n",
      " 29%|██▉       | 6.25M/21.5M [00:10<00:25, 632kB/s]\n",
      " 30%|██▉       | 6.38M/21.5M [00:10<00:24, 655kB/s]\n",
      " 30%|███       | 6.50M/21.5M [00:10<00:24, 647kB/s]\n",
      " 31%|███       | 6.62M/21.5M [00:10<00:24, 642kB/s]\n",
      " 31%|███▏      | 6.75M/21.5M [00:11<00:24, 636kB/s]\n",
      " 32%|███▏      | 6.88M/21.5M [00:11<00:24, 632kB/s]\n",
      " 33%|███▎      | 7.00M/21.5M [00:11<00:23, 644kB/s]\n",
      " 33%|███▎      | 7.12M/21.5M [00:11<00:23, 652kB/s]\n",
      " 34%|███▎      | 7.25M/21.5M [00:11<00:23, 643kB/s]\n",
      " 34%|███▍      | 7.38M/21.5M [00:12<00:23, 637kB/s]\n",
      " 35%|███▍      | 7.50M/21.5M [00:12<00:23, 634kB/s]\n",
      " 35%|███▌      | 7.62M/21.5M [00:12<00:23, 629kB/s]\n",
      " 36%|███▌      | 7.75M/21.5M [00:12<00:22, 653kB/s]\n",
      " 37%|███▋      | 7.88M/21.5M [00:12<00:22, 645kB/s]\n",
      " 37%|███▋      | 8.00M/21.5M [00:13<00:22, 639kB/s]\n",
      " 38%|███▊      | 8.12M/21.5M [00:13<00:22, 636kB/s]\n",
      " 38%|███▊      | 8.25M/21.5M [00:13<00:22, 633kB/s]\n",
      " 39%|███▉      | 8.38M/21.5M [00:13<00:22, 626kB/s]\n",
      " 39%|███▉      | 8.50M/21.5M [00:13<00:21, 649kB/s]\n",
      " 40%|████      | 8.62M/21.5M [00:14<00:20, 650kB/s]\n",
      " 41%|████      | 8.75M/21.5M [00:14<00:20, 639kB/s]\n",
      " 41%|████      | 8.88M/21.5M [00:14<00:21, 620kB/s]\n",
      " 42%|████▏     | 9.00M/21.5M [00:14<00:20, 627kB/s]\n",
      " 42%|████▏     | 9.12M/21.5M [00:15<00:20, 629kB/s]\n",
      " 43%|████▎     | 9.25M/21.5M [00:15<00:19, 655kB/s]\n",
      " 44%|████▎     | 9.38M/21.5M [00:15<00:19, 646kB/s]\n",
      " 44%|████▍     | 9.50M/21.5M [00:15<00:19, 639kB/s]\n",
      " 45%|████▍     | 9.62M/21.5M [00:15<00:19, 635kB/s]\n",
      " 45%|████▌     | 9.75M/21.5M [00:16<00:19, 640kB/s]\n",
      " 46%|████▌     | 9.88M/21.5M [00:16<00:18, 652kB/s]\n",
      " 46%|████▋     | 10.0M/21.5M [00:16<00:19, 634kB/s]\n",
      " 47%|████▋     | 10.1M/21.5M [00:16<00:18, 641kB/s]\n",
      " 48%|████▊     | 10.2M/21.5M [00:16<00:18, 624kB/s]\n",
      " 48%|████▊     | 10.4M/21.5M [00:17<00:18, 638kB/s]\n",
      " 49%|████▉     | 10.5M/21.5M [00:17<00:18, 633kB/s]\n",
      " 49%|████▉     | 10.6M/21.5M [00:17<00:17, 653kB/s]\n",
      " 50%|████▉     | 10.8M/21.5M [00:17<00:17, 645kB/s]\n",
      " 51%|█████     | 10.9M/21.5M [00:17<00:17, 643kB/s]\n",
      " 51%|█████     | 11.0M/21.5M [00:18<00:17, 634kB/s]\n",
      " 52%|█████▏    | 11.1M/21.5M [00:18<00:17, 622kB/s]\n",
      " 52%|█████▏    | 11.2M/21.5M [00:18<00:17, 632kB/s]\n",
      " 53%|█████▎    | 11.4M/21.5M [00:18<00:16, 628kB/s]\n",
      " 53%|█████▎    | 11.5M/21.5M [00:18<00:16, 657kB/s]\n",
      " 54%|█████▍    | 11.6M/21.5M [00:19<00:16, 645kB/s]\n",
      " 55%|█████▍    | 11.8M/21.5M [00:19<00:18, 565kB/s]\n",
      " 55%|█████▌    | 11.9M/21.5M [00:20<00:32, 310kB/s]\n",
      " 56%|█████▌    | 12.0M/21.5M [00:20<00:30, 332kB/s]\n",
      " 56%|█████▋    | 12.1M/21.5M [00:20<00:27, 364kB/s]\n",
      " 57%|█████▋    | 12.2M/21.5M [00:21<00:25, 375kB/s]\n",
      " 57%|█████▋    | 12.4M/21.5M [00:21<00:23, 416kB/s]\n",
      " 58%|█████▊    | 12.5M/21.5M [00:21<00:19, 474kB/s]\n",
      " 59%|█████▊    | 12.6M/21.5M [00:21<00:18, 510kB/s]\n",
      " 59%|█████▉    | 12.8M/21.5M [00:22<00:16, 545kB/s]\n",
      " 60%|█████▉    | 12.9M/21.5M [00:22<00:16, 564kB/s]\n",
      " 60%|██████    | 13.0M/21.5M [00:22<00:15, 581kB/s]\n",
      " 61%|██████    | 13.1M/21.5M [00:22<00:14, 612kB/s]\n",
      " 62%|██████▏   | 13.2M/21.5M [00:22<00:14, 618kB/s]\n",
      " 62%|██████▏   | 13.4M/21.5M [00:23<00:13, 623kB/s]\n",
      " 63%|██████▎   | 13.5M/21.5M [00:23<00:13, 620kB/s]\n",
      " 63%|██████▎   | 13.6M/21.5M [00:23<00:13, 619kB/s]\n",
      " 64%|██████▍   | 13.8M/21.5M [00:23<00:13, 624kB/s]\n",
      " 64%|██████▍   | 13.9M/21.5M [00:23<00:12, 624kB/s]\n",
      " 65%|██████▌   | 14.0M/21.5M [00:24<00:12, 620kB/s]\n",
      " 66%|██████▌   | 14.1M/21.5M [00:24<00:12, 625kB/s]\n",
      " 66%|██████▌   | 14.2M/21.5M [00:24<00:12, 627kB/s]\n",
      " 67%|██████▋   | 14.4M/21.5M [00:24<00:12, 624kB/s]\n",
      " 67%|██████▋   | 14.5M/21.5M [00:24<00:12, 601kB/s]\n",
      " 68%|██████▊   | 14.6M/21.5M [00:25<00:13, 539kB/s]\n",
      " 69%|██████▊   | 14.8M/21.5M [00:25<00:14, 501kB/s]\n",
      " 69%|██████▉   | 14.9M/21.5M [00:26<00:22, 308kB/s]\n",
      " 70%|██████▉   | 15.0M/21.5M [00:26<00:21, 323kB/s]\n",
      " 70%|███████   | 15.1M/21.5M [00:27<00:18, 359kB/s]\n",
      " 71%|███████   | 15.2M/21.5M [00:27<00:15, 412kB/s]\n",
      " 71%|███████▏  | 15.4M/21.5M [00:27<00:14, 457kB/s]\n",
      " 72%|███████▏  | 15.5M/21.5M [00:27<00:13, 464kB/s]\n",
      " 73%|███████▎  | 15.6M/21.5M [00:27<00:12, 500kB/s]\n",
      " 73%|███████▎  | 15.8M/21.5M [00:28<00:11, 522kB/s]\n",
      " 74%|███████▎  | 15.9M/21.5M [00:28<00:10, 586kB/s]\n",
      " 74%|███████▍  | 16.0M/21.5M [00:28<00:09, 597kB/s]\n",
      " 75%|███████▍  | 16.1M/21.5M [00:28<00:09, 604kB/s]\n",
      " 75%|███████▌  | 16.2M/21.5M [00:28<00:09, 611kB/s]\n",
      " 76%|███████▌  | 16.4M/21.5M [00:29<00:09, 589kB/s]\n",
      " 77%|███████▋  | 16.5M/21.5M [00:29<00:08, 602kB/s]\n",
      " 77%|███████▋  | 16.6M/21.5M [00:29<00:08, 602kB/s]\n",
      " 78%|███████▊  | 16.8M/21.5M [00:29<00:08, 609kB/s]\n",
      " 78%|███████▊  | 16.9M/21.5M [00:30<00:07, 619kB/s]\n",
      " 79%|███████▉  | 17.0M/21.5M [00:30<00:07, 646kB/s]\n",
      " 80%|███████▉  | 17.1M/21.5M [00:30<00:07, 637kB/s]\n",
      " 80%|████████  | 17.2M/21.5M [00:30<00:07, 634kB/s]\n",
      " 81%|████████  | 17.4M/21.5M [00:30<00:06, 633kB/s]\n",
      " 81%|████████▏ | 17.5M/21.5M [00:31<00:06, 634kB/s]\n",
      " 82%|████████▏ | 17.6M/21.5M [00:31<00:06, 626kB/s]\n",
      " 82%|████████▏ | 17.8M/21.5M [00:31<00:06, 643kB/s]\n",
      " 83%|████████▎ | 17.9M/21.5M [00:31<00:05, 653kB/s]\n",
      " 84%|████████▎ | 18.0M/21.5M [00:31<00:05, 639kB/s]\n",
      " 84%|████████▍ | 18.1M/21.5M [00:32<00:05, 638kB/s]\n",
      " 85%|████████▍ | 18.2M/21.5M [00:32<00:05, 631kB/s]\n",
      " 85%|████████▌ | 18.4M/21.5M [00:32<00:05, 628kB/s]\n",
      " 86%|████████▌ | 18.5M/21.5M [00:32<00:04, 659kB/s]\n",
      " 87%|████████▋ | 18.6M/21.5M [00:32<00:04, 638kB/s]\n",
      " 87%|████████▋ | 18.8M/21.5M [00:33<00:04, 636kB/s]\n",
      " 88%|████████▊ | 18.9M/21.5M [00:33<00:04, 632kB/s]\n",
      " 88%|████████▊ | 19.0M/21.5M [00:33<00:04, 622kB/s]\n",
      " 89%|████████▉ | 19.1M/21.5M [00:33<00:04, 628kB/s]\n",
      " 89%|████████▉ | 19.2M/21.5M [00:33<00:03, 602kB/s]\n",
      " 90%|█████████ | 19.4M/21.5M [00:34<00:03, 607kB/s]\n",
      " 91%|█████████ | 19.5M/21.5M [00:34<00:04, 472kB/s]\n",
      " 91%|█████████ | 19.6M/21.5M [00:34<00:04, 447kB/s]\n",
      " 92%|█████████▏| 19.8M/21.5M [00:35<00:05, 325kB/s]\n",
      " 92%|█████████▏| 19.9M/21.5M [00:35<00:04, 391kB/s]\n",
      " 93%|█████████▎| 20.0M/21.5M [00:36<00:04, 329kB/s]\n",
      " 93%|█████████▎| 20.1M/21.5M [00:36<00:04, 354kB/s]\n",
      " 94%|█████████▍| 20.2M/21.5M [00:36<00:03, 359kB/s]\n",
      " 95%|█████████▍| 20.4M/21.5M [00:37<00:03, 343kB/s]\n",
      " 95%|█████████▌| 20.5M/21.5M [00:37<00:03, 325kB/s]\n",
      " 96%|█████████▌| 20.6M/21.5M [00:38<00:02, 381kB/s]\n",
      " 96%|█████████▋| 20.8M/21.5M [00:38<00:01, 430kB/s]\n",
      " 97%|█████████▋| 20.9M/21.5M [00:38<00:01, 475kB/s]\n",
      " 98%|█████████▊| 21.0M/21.5M [00:38<00:01, 474kB/s]\n",
      " 98%|█████████▊| 21.1M/21.5M [00:39<00:00, 438kB/s]\n",
      " 99%|█████████▊| 21.2M/21.5M [00:39<00:00, 301kB/s]\n",
      " 99%|█████████▉| 21.4M/21.5M [00:40<00:00, 318kB/s]\n",
      "100%|█████████▉| 21.5M/21.5M [00:40<00:00, 363kB/s]\n",
      "100%|██████████| 21.5M/21.5M [00:40<00:00, 558kB/s]\n",
      "New https://pypi.org/project/ultralytics/8.2.51 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.196  Python-3.11.9 torch-2.3.1+cpu CPU (Intel Core(TM) i7-8565U 1.80GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=d:\\DatTruong\\All\\2025\\AI_Engineer\\20.Project\\4.Autonomous_Vehicle\\src\\Vietnam-Traffic-Sign-Detection-6/data.yaml, epochs=25, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\envs\\prj4\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 118, in __init__\n",
      "    self.data = check_det_dataset(self.args.data)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Conda\\envs\\prj4\\Lib\\site-packages\\ultralytics\\data\\utils.py\", line 301, in check_det_dataset\n",
      "    raise FileNotFoundError(m)\n",
      "FileNotFoundError: \n",
      "Dataset 'd://DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/src/Vietnam-Traffic-Sign-Detection-6/data.yaml' images not found ⚠️, missing path 'D:\\DatTruong\\All\\2025\\AI_Engineer\\20.Project\\4.Autonomous_Vehicle\\src\\Vietnam-Traffic-Sign-Detection-6\\Vietnam-Traffic-Sign-Detection-6\\valid\\images'\n",
      "Note dataset download directory is 'D:\\DatTruong\\All\\2025\\AI_Engineer\\20.Project\\4.Autonomous_Vehicle\\src\\datasets'. You can update this in 'C:\\Users\\ADMIN\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"D:\\Conda\\envs\\prj4\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"D:\\Conda\\envs\\prj4\\Lib\\site-packages\\ultralytics\\cfg\\__init__.py\", line 445, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Conda\\envs\\prj4\\Lib\\site-packages\\ultralytics\\engine\\model.py\", line 336, in train\n",
      "    self.trainer = (trainer or self._smart_load('trainer'))(overrides=args, _callbacks=self.callbacks)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Conda\\envs\\prj4\\Lib\\site-packages\\ultralytics\\engine\\trainer.py\", line 122, in __init__\n",
      "    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error ❌ {e}\")) from e\n",
      "RuntimeError: Dataset 'd://DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/src/Vietnam-Traffic-Sign-Detection-6/data.yaml' error  \n",
      "Dataset 'd://DatTruong/All/2025/AI_Engineer/20.Project/4.Autonomous_Vehicle/src/Vietnam-Traffic-Sign-Detection-6/data.yaml' images not found , missing path 'D:\\DatTruong\\All\\2025\\AI_Engineer\\20.Project\\4.Autonomous_Vehicle\\src\\Vietnam-Traffic-Sign-Detection-6\\Vietnam-Traffic-Sign-Detection-6\\valid\\images'\n",
      "Note dataset download directory is 'D:\\DatTruong\\All\\2025\\AI_Engineer\\20.Project\\4.Autonomous_Vehicle\\src\\datasets'. You can update this in 'C:\\Users\\ADMIN\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=640 plots=True"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
